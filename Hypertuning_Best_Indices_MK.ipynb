{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_TY8n9julXs",
    "outputId": "78599af9-0204-46e6-888c-3b4aa905e365"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/mnt/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zoP4da_5yUQW"
   },
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "file_path = '/mnt/drive/MyDrive/canola/canola_spectrum_index.csv'  # Replace with your file path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Separate inputs and output\n",
    "X = data.drop(columns=['salinity', 'variety'])\n",
    "y = data['salinity']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7641)\n",
    "\n",
    "# Define the model\n",
    "model = RidgeClassifier(random_state=7641)\n",
    "\n",
    "# Define the parameter grid for random search\n",
    "param_distributions = {\n",
    "    'alpha': np.logspace(-4, 4, 50),  # Ridge regularization strength\n",
    "    'tol': [1e-4, 1e-3, 1e-2, 1e-1, 1],  # Tolerance for stopping criteria\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'lbfgs'],  # Different solvers\n",
    "}\n",
    "\n",
    "# Perform Randomized Search with cross-validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,  # Number of random configurations to sample\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',  # Evaluation metric\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=7641,  # For reproducibility\n",
    "    verbose=1  # Show progress\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and accuracy\n",
    "best_model = random_search.best_estimator_\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy on Test Set: {test_accuracy:.4f}\")\n",
    "\n",
    "# Get feature importance (coefficients)\n",
    "feature_importance = np.mean(np.abs(best_model.coef_), axis=0)\n",
    "\n",
    "# Create a dataframe for feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "\n",
    "# Sort the features by importance and display the top 10\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(importance_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('/mnt/drive/MyDrive/canola/canola_spectrum_index.csv')\n",
    "\n",
    "# Separate inputs and output\n",
    "X = data.drop(columns=['salinity', 'variety'])\n",
    "# X = data.filter(regex=\"^Band\")\n",
    "y = data['salinity']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7641)\n",
    "\n",
    "# Define the important features (your custom bands)\n",
    "# important_features = ['CIRE', 'Band_180', 'Band_223', 'Band_247', 'Band_181'\n",
    "#         ]\n",
    "important_features = ['Band_180', 'Band_178', 'Band_181', 'Band_222', 'Band_179', 'Band_201','Band_223'\n",
    "        ]\n",
    "\n",
    "# List of formulas with placeholders (X, Y, Z, W)\n",
    "formulas = [\n",
    "    \"(1 / X) - (1 / Y)\",\n",
    "    \"(Z - W) / (Z + X)\",\n",
    "    \"((1 / X) - (1 / Y)) / Z\",\n",
    "    \"((0.1 * Z) - W) / ((0.1 * Z) + W)\",\n",
    "    \"(X * Y) / Z\",\n",
    "    \"(Z) / (X) - 1\",\n",
    "    \"(X / Y) - 1\",\n",
    "    \"(1 / X) - (1 / Z)\",\n",
    "    \"(1 / W) - (1 / Y)\",\n",
    "    \"(Z * X) / (Y * Y)\",\n",
    "    \"(X - Y) / (X - W)\",\n",
    "    \"(Y * Z) / (X * X)\",\n",
    "    \"2.5 * (Z - X) / (Z + 6 * X - 7.5 * W + 1)\",\n",
    "    \"2 * X - Y - Z\",\n",
    "    \"(2 * X - Y - Z) / (2 * X + Y + Z)\",\n",
    "    \"(Z - (X + Y)) / (Z + (X + Y))\",\n",
    "    \"(Z - X) / (Z + X + 0.16)\",\n",
    "    \"(X - (Y + Z)) / (X + (Y + Z))\",\n",
    "    \"(Z - Y) / (Z + X)\",\n",
    "    \"((X - Y) - 0.2 * (X - Z)) * (X / Y)\",\n",
    "    \"(X**2 - Y**2) / (X**2 + Y**2)\",\n",
    "    \"(Z - X) / (Z + X - 2 * W)\",\n",
    "    \"0.5 * (2 * Z + 1 - np.sqrt((2 * Z + 1)**2 - 8 * (Z - X)))\",\n",
    "    \"(Z - X) / (Z + X)\",\n",
    "    \"(Z - Y) / (Z + Y)\",\n",
    "    \"(Z - X) / (Z + X + 0.16)\",\n",
    "    \"(Y - X) / Z\",\n",
    "    \"(Z - X) / np.sqrt(Z + X)\",\n",
    "    \"(X**2 - Y * Z) / (X**2 + Y * Z)\",\n",
    "    \"0.5 * (120 * (Z - X) - 200 * (Y - X))\"\n",
    "]\n",
    "\n",
    "# Function to evaluate a given formula's contribution to model accuracy\n",
    "def evaluate_formula(X_train, X_test, y_train, y_test, new_feature_train, new_feature_test, formula):\n",
    "    # Add the new feature to the dataset\n",
    "    X_train_extended = X_train.copy()\n",
    "    X_test_extended = X_test.copy()\n",
    "    X_train_extended[formula] = new_feature_train\n",
    "    X_test_extended[formula] = new_feature_test\n",
    "\n",
    " # Train the RidgeClassifier with hyper-tuned parameters\n",
    "model = RidgeClassifier(alpha=0.12648552168552957, tol=0.1, solver='cholesky', random_state=7641)\n",
    "model.fit(X_train_extended, y_train)\n",
    "\n",
    "\n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = model.predict(X_test_extended)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate all combinations of X, Y, Z, W with important features\n",
    "best_formula = None\n",
    "best_accuracy = 0\n",
    "\n",
    "total_formulas_tried = 0\n",
    "\n",
    "for formula in formulas:\n",
    "    # Iterate over all combinations of your important features in place of X, Y, Z, W\n",
    "    for x, y, z, w in itertools.permutations(important_features, 4):\n",
    "        # Replace placeholders (X, Y, Z, W) with actual feature names\n",
    "        adjusted_formula = formula.replace('X', x).replace('Y', y).replace('Z', z).replace('W', w)\n",
    "\n",
    "        # Calculate the new feature values for both training and testing sets using pandas.eval()\n",
    "        try:\n",
    "            new_feature_train = X_train.eval(adjusted_formula, engine='python')\n",
    "            new_feature_test = X_test.eval(adjusted_formula, engine='python')\n",
    "        except (ZeroDivisionError, TypeError, NameError, ValueError):\n",
    "            continue  # Skip this formula if it causes an error (e.g., division by zero, invalid operations)\n",
    "\n",
    "        # Evaluate the accuracy of the new feature added to the model\n",
    "        accuracy = evaluate_formula(X_train, X_test, y_train, y_test, new_feature_train, new_feature_test, adjusted_formula)\n",
    "\n",
    "        # Update the best formula if this one is better\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_formula = adjusted_formula\n",
    "            print(f\"New Best Formula: {best_formula} -> Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "        total_formulas_tried += 1\n",
    "\n",
    "print(f\"\\nTotal Formulas Tried: {total_formulas_tried}\")\n",
    "print(f\"Best Formula Found: {best_formula} -> Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Final Model with Best Formula\n",
    "X_train[best_formula] = X_train.eval(best_formula, engine='python')\n",
    "X_test[best_formula] = X_test.eval(best_formula, engine='python')\n",
    "\n",
    "model = RidgeClassifier(alpha=1.0, random_state=7641)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nFinal Model Accuracy with Best Formula: {final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('/mnt/drive/MyDrive/canola/canola_spectrum_index_AND_newindexafterhypertuning.csv')\n",
    "\n",
    "# Separate inputs and output\n",
    "# X = data.drop(columns=['salinity', 'variety'])\n",
    "X = data[\n",
    "    ['NEW_index', 'CVI', 'RGBVI', 'CIG', 'BWDRVI', 'Band_179', 'Band_180', 'Band_178', 'Band_181', 'Band_222', 'Band_223',\n",
    "    'Band_201', 'Band_200', 'Band_203', 'Band_202', 'Band_256',\n",
    "    'Band_238', 'Band_207',  'Band_172',  'Band_206',\n",
    "     'Band_210'\n",
    "    ]]\n",
    "y = data['salinity']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7641)\n",
    "\n",
    "# Define the important features (your custom bands)\n",
    "important_features = ['Band_179', 'Band_180', 'Band_178', 'Band_181', 'Band_222', 'Band_223',\n",
    "    'Band_201', 'Band_200', 'Band_203', 'Band_202', 'Band_256',\n",
    "    'Band_238', 'Band_207',  'Band_172',  'Band_206',\n",
    "     'Band_210']\n",
    "\n",
    "# List of formulas with placeholders (X, Y, Z, W), optimized by removing identical or redundant ones\n",
    "formulas = [\n",
    "    \"(1 / X) - (1 / Y)\",\n",
    "    \"(Z - W) / (Z + X)\",\n",
    "    \"((1 / X) - (1 / Y)) / Z\",\n",
    "    \"((0.1 * Z) - W) / ((0.1 * Z) + W)\",\n",
    "    \"(X * Y) / Z\",\n",
    "    \"(Z / X) - 1\",\n",
    "    \"(X / Y) - 1\",\n",
    "    \"(1 / X) - (1 / Z)\",\n",
    "    \"(1 / W) - (1 / Y)\",\n",
    "    \"(Z * X) / (Y * Y)\",\n",
    "    \"(X - Y) / (X - W)\",\n",
    "    \"(Y * Z) / (X * X)\",\n",
    "    \"2.5 * (Z - X) / (Z + 6 * X - 7.5 * W + 1)\",\n",
    "    \"2 * X - Y - Z\",\n",
    "    \"(2 * X - Y - Z) / (2 * X + Y + Z)\",\n",
    "    \"(Z - (X + Y)) / (Z + (X + Y))\",\n",
    "    \"(Z - X) / (Z + X + 0.16)\",\n",
    "    \"(X - (Y + Z)) / (X + (Y + Z))\",\n",
    "    \"(Z - Y) / (Z + X)\",\n",
    "    \"((X - Y) - 0.2 * (X - Z)) * (X / Y)\",\n",
    "    \"(X**2 - Y**2) / (X**2 + Y**2)\",\n",
    "    \"(Z - X) / (Z + X - 2 * W)\",\n",
    "    \"0.5 * (2 * Z + 1 - np.sqrt((2 * Z + 1)**2 - 8 * (Z - X)))\",\n",
    "    \"(Z - Y) / (Z + Y)\",\n",
    "    \"(Y - X) / Z\",\n",
    "    \"(Z - X) / np.sqrt(Z + X)\",\n",
    "    \"(X**2 - Y * Z) / (X**2 + Y * Z)\",\n",
    "    \"0.5 * (120 * (Z - X) - 200 * (Y - X))\"\n",
    "]\n",
    "\n",
    "# Function to evaluate a given formula's contribution to model accuracy\n",
    "def evaluate_formula(X_train, X_test, y_train, y_test, new_feature_train, new_feature_test, formula):\n",
    "    # Add the new feature to the dataset\n",
    "    X_train_extended = X_train.copy()\n",
    "    X_test_extended = X_test.copy()\n",
    "    X_train_extended[formula] = new_feature_train\n",
    "    X_test_extended[formula] = new_feature_test\n",
    "\n",
    "    # Train the RidgeClassifier with hyper-tuned parameters\n",
    "    model = RidgeClassifier(alpha=0.12648552168552957, tol=0.1, solver='cholesky', random_state=7641)\n",
    "    model.fit(X_train_extended, y_train)\n",
    "\n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = model.predict(X_test_extended)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate all combinations of X, Y, Z, W with important features\n",
    "best_formula = None\n",
    "best_accuracy = 0\n",
    "\n",
    "total_formulas_tried = 0\n",
    "\n",
    "for formula in formulas:\n",
    "    # Iterate over all combinations of your important features in place of X, Y, Z, W\n",
    "    for x, y, z, w in itertools.permutations(important_features, 4):\n",
    "        # Replace placeholders (X, Y, Z, W) with actual feature names\n",
    "        adjusted_formula = formula.replace('X', x).replace('Y', y).replace('Z', z).replace('W', w)\n",
    "\n",
    "        # Calculate the new feature values for both training and testing sets using pandas.eval()\n",
    "        try:\n",
    "            new_feature_train = X_train.eval(adjusted_formula, engine='python')\n",
    "            new_feature_test = X_test.eval(adjusted_formula, engine='python')\n",
    "        except (ZeroDivisionError, TypeError, NameError, ValueError):\n",
    "            continue  # Skip this formula if it causes an error (e.g., division by zero, invalid operations)\n",
    "\n",
    "        # Evaluate the accuracy of the new feature added to the model\n",
    "        accuracy = evaluate_formula(X_train, X_test, y_train, y_test, new_feature_train, new_feature_test, adjusted_formula)\n",
    "\n",
    "        # Update the best formula if this one is better\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_formula = adjusted_formula\n",
    "            print(f\"New Best Formula: {best_formula} -> Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "        total_formulas_tried += 1\n",
    "\n",
    "print(f\"\\nTotal Formulas Tried: {total_formulas_tried}\")\n",
    "print(f\"Best Formula Found: {best_formula} -> Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Final Model with Best Formula\n",
    "X_train[best_formula] = X_train.eval(best_formula, engine='python')\n",
    "X_test[best_formula] = X_test.eval(best_formula, engine='python')\n",
    "\n",
    "# Re-train the model with the best formula included\n",
    "model = RidgeClassifier(alpha=0.12648552168552957, tol=0.1, solver='cholesky', random_state=7641)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nFinal Model Accuracy with Best Formula: {final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dW2Jc59NhycK",
    "outputId": "6b0ebe8d-f659-4ed0-ca85-87b76312b8da"
   },
   "outputs": [],
   "source": [
    "# Add the new feature (best formula) to the original data\n",
    "data[best_formula] = data.eval(best_formula, engine='python')\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "data.to_csv('/mnt/drive/MyDrive/canola/canola_spectrum_index_new_index.csv', index=False)\n",
    "\n",
    "print(f\"The new feature '{best_formula}' has been added as the last column and saved to 'updated_file_with_new_band.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
