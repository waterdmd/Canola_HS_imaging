{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d30d289-97bb-46a6-8c96-660bdd9da66d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spectral\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the hyperspectral image\n",
    "bip_file_path = 'file_path.bip'  # Replace with your BIP file path\n",
    "hdr_file_path = 'file_path.hdr'  # Replace with your HDR file path\n",
    "\n",
    "# Read the hyperspectral image\n",
    "img = spectral.open_image(hdr_file_path)\n",
    "data = img.load()\n",
    "\n",
    "# Get the shape of the data cube\n",
    "n_rows, n_cols, n_bands = data.shape\n",
    "\n",
    "# Reshape the data to have each pixel in a row\n",
    "reshaped_data = data.reshape((n_rows * n_cols, n_bands))\n",
    "\n",
    "# Create a DataFrame with the reshaped data\n",
    "wavelengths = [\n",
    "    391.06, 393.06, 395.05, 397.05, 399.05, 401.04, 403.04, 405.04, 407.04, 409.05,\n",
    "    411.05, 413.05, 415.06, 417.06, 419.06, 421.07, 423.08, 425.09, 427.1, 429.1,\n",
    "    431.12, 433.13, 435.14, 437.16, 439.17, 441.18, 443.2, 445.22, 447.24, 449.26,\n",
    "    451.27, 453.28, 455.32, 457.34, 459.36, 461.38, 463.4, 465.42, 467.45, 469.48,\n",
    "    471.5, 473.53, 475.56, 477.59, 479.62, 481.65, 483.68, 485.72, 487.75, 489.78,\n",
    "    491.82, 493.86, 495.89, 497.93, 499.97, 502.01, 504.05, 506.09, 508.13, 510.18,\n",
    "    512.22, 514.26, 516.31, 518.36, 520.4, 522.45, 524.5, 526.54, 528.6, 530.64,\n",
    "    532.7, 534.75, 536.81, 538.86, 540.92, 542.96, 545.02, 547.08, 549.14, 551.21,\n",
    "    553.26, 555.33, 557.38, 559.44, 561.5, 563.58, 565.64, 567.71, 569.77, 571.84,\n",
    "    573.9, 575.98, 578.04, 580.12, 582.18, 584.26, 586.33, 588.4, 590.48, 592.56,\n",
    "    594.63, 596.71, 598.79, 600.86, 602.94, 605.02, 607.11, 609.19, 611.27, 613.36,\n",
    "    615.44, 617.52, 619.61, 621.7, 623.78, 625.88, 627.96, 630.06, 632.14, 634.24,\n",
    "    636.33, 638.42, 640.52, 642.62, 644.71, 646.81, 648.9, 651, 653.1, 655.2,\n",
    "    657.3, 659.4, 661.5, 663.61, 665.72, 667.82, 669.92, 672.04, 674.14, 676.25,\n",
    "    678.36, 680.47, 682.58, 684.69, 686.8, 688.92, 691.03, 693.14, 695.26, 697.38,\n",
    "    699.49, 701.61, 703.73, 705.85, 707.97, 710.09, 712.22, 714.34, 716.46, 718.59,\n",
    "    720.71, 722.84, 724.96, 727.1, 729.22, 731.36, 733.48, 735.62, 737.74, 739.88,\n",
    "    742.02, 744.15, 746.29, 748.42, 750.56, 752.7, 754.84, 756.98, 759.12, 761.26,\n",
    "    763.4, 765.54, 767.68, 769.82, 771.98, 774.12, 776.26, 778.42, 780.56, 782.71,\n",
    "    784.86, 787.02, 789.16, 791.32, 793.47, 795.62, 797.78, 799.94, 802.09, 804.25,\n",
    "    806.41, 808.57, 810.73, 812.89, 815.05, 817.21, 819.38, 821.54, 823.71, 825.87,\n",
    "    828.04, 830.2, 832.38, 834.54, 836.71, 838.88, 841.06, 843.22, 845.4, 847.58,\n",
    "    849.75, 851.92, 854.1, 856.28, 858.46, 860.64, 862.82, 865, 867.18, 869.36,\n",
    "    871.54, 873.72, 875.92, 878.1, 880.29, 882.47, 884.66, 886.85, 889.04, 891.23,\n",
    "    893.42, 895.61, 897.8, 900, 902.19, 904.39, 906.58, 908.78, 910.98, 913.18,\n",
    "    915.38, 917.58, 919.78, 921.98, 924.18, 926.39, 928.59, 930.8, 933, 935.21,\n",
    "    937.42, 939.62, 941.84, 944.04, 946.26, 948.46, 950.68, 952.9, 955.1, 957.32,\n",
    "    959.54, 961.76, 963.97, 966.2, 968.4, 970.62, 972.86, 975.08, 977.3, 979.52,\n",
    "    981.74, 983.96, 986.2, 988.42, 990.64, 992.88, 995.1, 997.34, 999.56, 1001.8,\n",
    "    1004.03, 1006.26, 1008.5, 1010.73, 1012.96, 1015.2, 1017.44, 1019.68, 1021.92, 1024.16\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(reshaped_data, columns=wavelengths)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "\n",
    "output_file_path = 'file_path.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f\"Data has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54bd312-dce9-4ec6-8392-5bf91627cf10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of input CSV file paths\n",
    "input_files = [\n",
    "    'file_path.csv',  # Replace with your file paths\n",
    "    'file_path.csv',\n",
    "    'file_path.csv',\n",
    "    'file_path.csv'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Read the first 500 rows from each file (excluding the header) and append to the list\n",
    "for file in input_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df.iloc[1:501])  # Select rows from 1 to 500 (500 rows excluding header)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Add the header from the first file\n",
    "header = pd.read_csv(input_files[0], nrows=0)\n",
    "combined_df.columns = header.columns\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "output_file_path = 'file_path.csv'  # Replace with your desired output file path\n",
    "combined_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Combined data has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e52519-a344-4e53-8864-54513bea7efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of input CSV file paths\n",
    "input_files = [\n",
    "    'file_path.csv',  # Replace with your file paths\n",
    "    'file_path.csv',\n",
    "    'file_path.csv',\n",
    "    'file_path.csv',\n",
    "    'file_path.csv',\n",
    "    'file_path.csv'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Read the first 1500 rows from each file (excluding the header) and append to the list\n",
    "for file in input_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df.iloc[1:])  # Select rows from 1 to 1500 (1500 rows excluding header)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Read the header from the first file\n",
    "header = pd.read_csv(input_files[0], nrows=0)\n",
    "combined_df.columns = header.columns\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "output_file_path = 'file_path.csv'  # Replace with your desired output file path\n",
    "combined_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Combined data has been saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
